{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Bayes Boundary Data (3/3):\n",
    "This is the last of three scripts meant to be run in order. We use a naive bayes model for our predictions, and en route we create and store cutoffs for our plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Necessary Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division # Not neccessary in Python 3 and later\n",
    "import scipy\n",
    "from math import exp,sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Functions to Estimate Probability Cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Assuming normal distributions we estimate their moments, \n",
    "#then calculate raw probabilities for each subjects data point, \n",
    "#finally returning the true estimated probability.\n",
    "\n",
    "def generate_probability(data, adhd):\n",
    "    #calculating moments:\n",
    "    adhdMu = scipy.mean(data[adhd == 1])    \n",
    "    adhdSD = scipy.std(data[adhd == 1])\n",
    "    healthyMu = scipy.mean(data[adhd == 0])\n",
    "    healthySD = scipy.std(data[adhd == 0])\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    adhdADHDProbs = np.zeros(np.shape(data)[0])\n",
    "    healthyProbs = np.zeros(np.shape(data)[0])\n",
    "    \n",
    "    for i in np.arange(np.shape(data)[0]):\n",
    "        adhdADHDProbs[i] = scipy.stats.norm.pdf(data[i], loc = adhdMu, scale = adhdSD)\n",
    "        healthyProbs[i] = scipy.stats.norm.pdf(data[i], loc = healthyMu, scale = healthySD)\n",
    "            \n",
    "    return adhdADHDProbs/(adhdADHDProbs + healthyProbs), 1 - (adhdADHDProbs/(adhdADHDProbs + healthyProbs))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#intermediary function for finding the bayes boundary given two diferent distributions\n",
    "def get_distribution_cutoff(data):\n",
    "\n",
    "    omissionErrorsCutoffs = find_boundary(data[:, 1], data[:, 2], data[:, 3])\n",
    "\n",
    "    commissionErrorsCutoffs = find_boundary(data[:, 4], data[:, 5], data[:, 6])\n",
    "    \n",
    "    targetsRTVCutoffs = find_boundary(data[:, 7], data[:, 8], data[:, 9])\n",
    "    \n",
    "    dPrimeCutoffs = find_boundary(data[:, 10], data[:, 11], data[:, 12])\n",
    "    \n",
    "    betaCutoffs = find_boundary(data[:, 13], data[:, 14], data[:, 15])\n",
    "    \n",
    "    theWholePointOfThisFunction = np.concatenate((np.asarray(omissionErrorsCutoffs), \n",
    "                                              np.asarray(commissionErrorsCutoffs), \n",
    "                                              np.asarray(targetsRTVCutoffs), \n",
    "                                              np.asarray(dPrimeCutoffs), \n",
    "                                              np.asarray(betaCutoffs)))\n",
    "\n",
    "    theWholePointOfThisFunction = np.ndarray.flatten(theWholePointOfThisFunction)\n",
    "\n",
    "    return theWholePointOfThisFunction\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function for finding the boundary\n",
    "def find_boundary(x, first, second):\n",
    "    truths = first < second\n",
    "    cutoffs = []\n",
    "    for i in np.arange(len(truths) - 1):\n",
    "        if truths[i] != truths[i + 1]:\n",
    "            cutoffs.append(x[np.int(i) + 1])\n",
    "    if len(cutoffs) < 2:\n",
    "        cutoffs.append(None)\n",
    "    return cutoffs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the meat of these three scripts. The function that takes all\n",
    "we have done up until now and calculates the features individual and cumulative prediction of adhd\n",
    "We use a naive bayes methodology inspired by this: \n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Constructing_a_classifier_from_the_probability_model\n",
    "\n",
    "Were we to seek to improve this model, we may want to switch out normal distributions for betas of the \n",
    "omissions and commission errors, and include gamma distributions for TargetsRTV\n",
    "Some caveats:\n",
    "    -From Yiming, naive bayes works poorly with highly correlated features, several of which ours are. \n",
    "It may be good to return and check the true correlations as we get more data.\n",
    "    -Naive Bayes is known for for not giving particularily accurate probability estimates, although their \n",
    "classification is usually right (IE the probabilities are on the right side of the midpoint). Because\n",
    "we are advertising the probability as showing where one is on the spectrum, we should revisit this as\n",
    "we get more data.\n",
    "\"\"\"\n",
    "def get_probabilities(data):\n",
    "    adhd = data[:, 5]\n",
    "    \n",
    "    #Here we are initializing everything to have the correct dimension so we can \n",
    "    #concatenate them in the future.\n",
    "    omissionADHDProbs = np.zeros((20, 1))\n",
    "    commissionADHDProbs = np.zeros((20,1))\n",
    "    targetRTVADHDProbs = np.zeros((20,1))\n",
    "    dPrimeADHDProbs = np.zeros((20,1))\n",
    "    betaADHDProbs = np.zeros((20,1))\n",
    "    priorsADHD = np.zeros((20,1))\n",
    "    totalRawProbabilityADHD = np.zeros((20,1))\n",
    "    \n",
    "    omissionHealthyProbs = np.zeros((20, 1))\n",
    "    commissionHealthyProbs = np.zeros((20,1))\n",
    "    targetRTVHealthyProbs = np.zeros((20,1))\n",
    "    dPrimeHealthyProbs = np.zeros((20,1))\n",
    "    betaHealthyProbs = np.zeros((20,1))\n",
    "    priorsHealthy = np.zeros((20,1))\n",
    "    totalRawProbabilityHealthy = np.zeros((20,1))\n",
    "    \n",
    "    #generating the individual probabilities:\n",
    "    omissionADHDProbs[:, 0], omissionHealthyProbs[:, 0] = generate_probability(data[:, 0], adhd)\n",
    "    commissionADHDProbs[:, 0], commissionHealthyProbs[:, 0] = generate_probability(data[:, 1], adhd)\n",
    "    targetRTVADHDProbs[:, 0], targetRTVHealthyProbs[:, 0] = generate_probability(data[:, 2], adhd)\n",
    "    dPrimeADHDProbs[:, 0], dPrimeHealthyProbs[:, 0] = generate_probability(data[:, 3], adhd)\n",
    "    betaADHDProbs[:, 0], betaHealthyProbs[:, 0] = generate_probability(data[:, 4], adhd)\n",
    "    \n",
    "    #Getting the total raw probability by multiplying all features\n",
    "    totalRawProbabilityADHD = multiply_5_arrays(omissionADHDProbs, \n",
    "                                                      commissionADHDProbs,\n",
    "                                                      targetRTVADHDProbs,\n",
    "                                                      dPrimeADHDProbs, \n",
    "                                                      betaADHDProbs)\n",
    "    totalRawProbabilityHealthy = multiply_5_arrays(omissionHealthyProbs,\n",
    "                                                        commissionHealthyProbs,\n",
    "                                                        targetRTVHealthyProbs,\n",
    "                                                        dPrimeHealthyProbs,\n",
    "                                                        betaHealthyProbs)\n",
    "    #Finding the priors using an identical method as the features. It could really be called a \n",
    "    #feature itself but ~\\_('_')_/~  \n",
    "    priorsADHD[:, 0], priorsHealthy[:, 0] = generate_probability(data[:, 6], adhd)\n",
    "\n",
    "    #getting the total probability\n",
    "    totalProbabilityADHD = np.zeros((20,1))\n",
    "    pADHD = np.multiply(priorsADHD, totalRawProbabilityADHD)\n",
    "    pHealthy = np.multiply(priorsHealthy, totalRawProbabilityHealthy)\n",
    "    pTotal = pADHD + pHealthy\n",
    "    totalProbabilityADHD = np.divide(pADHD,pTotal)\n",
    "        \n",
    "    \n",
    "    #Just for fun, here is our training accuracy:\n",
    "    count = 0\n",
    "    for i in np.arange(20):\n",
    "        if (np.round(totalProbabilityADHD[i]) == adhd[i]):\n",
    "            count = count + 1\n",
    "    print(\"training accuracy: \", 100 * count/20, \"%\")\n",
    "    \n",
    "    return np.concatenate((omissionADHDProbs,\n",
    "                           omissionHealthyProbs,\n",
    "                           commissionADHDProbs, \n",
    "                           commissionHealthyProbs,\n",
    "                           targetRTVADHDProbs,\n",
    "                           targetRTVHealthyProbs,\n",
    "                           dPrimeADHDProbs, \n",
    "                           dPrimeHealthyProbs,\n",
    "                           betaADHDProbs, \n",
    "                           betaHealthyProbs,\n",
    "                           totalRawProbabilityADHD, \n",
    "                           totalRawProbabilityHealthy,\n",
    "                           priorsADHD,\n",
    "                           totalProbabilityADHD),\n",
    "                          axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function for readability\n",
    "def multiply_5_arrays(a,b,c,d,e):\n",
    "    holder = np.multiply(a, b)\n",
    "    holder = np.multiply(holder, c)\n",
    "    holder = np.multiply(holder, d)\n",
    "    holder = np.multiply(holder, e)\n",
    "    return holder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DB connecting, pull, & insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializes connection info for database\n",
    "def connect():\n",
    "    return pymysql.connect(host = \"rm-j6cluj4576jdi6n6oo.mysql.rds.aliyuncs.com\",\n",
    "                           database = 'rnd_test', \n",
    "                           user='cognitiveleap', \n",
    "                           password= 'QWE@123456')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting data from DB\n",
    "\n",
    "def get_individual_data(CaseIds, raw):\n",
    "    #connect to db\n",
    "    db = connect()\n",
    "    \n",
    "    # prepare a cursor object using cursor() method\n",
    "    cursor = db.cursor()\n",
    "    dataPatient = []\n",
    "    dataSignal = []\n",
    "    dataSNAP = np.zeros((20,1))\n",
    "    # Prepare SQL query to INSERT a record into the database.\n",
    "    for i in CaseIds:\n",
    "        if raw:\n",
    "            sql = \"\"\"SELECT CasdId, OmissionErrors, CommissionErrors, TargetsRtVariability\n",
    "                     FROM cpt_output_results WHERE Block = 0 AND CasdId = \"\"\" + str(i) \n",
    "            cursor.execute(sql)\n",
    "            # Fetch all the rows in a list of lists.\n",
    "            results = np.asarray(cursor.fetchall())\n",
    "            dataPatient.append(results)\n",
    "            \n",
    "            sql = \"\"\"SELECT DPrime, Beta, ADHD FROM signal_detection WHERE Block = 0 AND CaseId = \"\"\" + str(i)\n",
    "            cursor.execute(sql)\n",
    "            # Fetch all the rows in a list of lists.\n",
    "            results = np.asarray(cursor.fetchall())\n",
    "            dataSignal.append(results)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            sql = \"SELECT PathLen, TimeActive, NumRot, TotalDeg, CasdId FROM head_features WHERE CasdId = %s \"% str(i)\n",
    "            #print(sql)\n",
    "            cursor.execute(sql)\n",
    "            results = np.asarray(cursor.fetchall())\n",
    "            if (len(results) > 0):\n",
    "                data.append(results[0])\n",
    "     \n",
    "\n",
    "    #odd error\n",
    "    \"\"\"   except:\n",
    "         print (\"Error: unable to fetch data\")\"\"\"\n",
    "    if raw:\n",
    "        sql = \"\"\"SELECT SNAPCombined FROM snap_hack\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        # Fetch all the rows in a list of lists.\n",
    "        results = np.asarray(cursor.fetchall())\n",
    "        dataSNAP[:, 0] = np.ndarray.flatten(results)\n",
    "\n",
    "\n",
    "    db.close()\n",
    "    dataPatient = np.concatenate(np.asarray(dataPatient))\n",
    "    dataSignal = np.concatenate(np.asarray(dataSignal))\n",
    "    return np.concatenate((dataPatient, dataSignal, dataSNAP), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#getting data from plotting vector tables\n",
    "def get_probability_data(raw):\n",
    "    #connect to db\n",
    "    db = connect()\n",
    "    \n",
    "    # prepare a cursor object using cursor() method\n",
    "    cursor = db.cursor()\n",
    "    data = []\n",
    "\n",
    "    if raw:\n",
    "        sql = \"\"\"SELECT * FROM bayes_bound_prob_plot\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        # Fetch all the rows in a list of lists.\n",
    "        results = np.asarray(cursor.fetchall())\n",
    "        data = np.asarray(results)\n",
    "\n",
    "    else:\n",
    "        sql = \"SELECT PathLen, TimeActive, NumRot, TotalDeg, CasdId FROM head_features WHERE CasdId = %s \"% str(i)\n",
    "        #print(sql)\n",
    "        cursor.execute(sql)\n",
    "        results = np.asarray(cursor.fetchall())\n",
    "        if (len(results) > 0):\n",
    "            data.append(results[0])\n",
    "     \n",
    "\n",
    "    \"\"\"except:\n",
    "         print (\"Error: unable to fetch data\")\"\"\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inserting created cutoofs for plots\n",
    "def insert_cutoffs(data):\n",
    "    data[np.equal(data,None)] = \"NULL\"\n",
    "    db = connect()\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO bayes_cutoffs (Id,\"\n",
    "    sql += \"OmissionErrorsCutoffOne,\" \n",
    "    sql += \"OmissionErrorsCutoffTwo,\"\n",
    "    sql += \"CommissionErrorsCutoffOne,\"\n",
    "    sql += \"CommissionErrorsCutoffTwo,\"\n",
    "    sql += \"TargetRTVCutoffOne, \"\n",
    "    sql += \"TargetRTVCutoffTwo, \"\n",
    "    sql += \"DPrimeCutoffOne, \"\n",
    "    sql += \"DPrimeCutoffTwo, \"\n",
    "    sql += \"BetaCutoffOne, \"\n",
    "    sql += \"BetaCutoffTwo )\"\n",
    "    sql += \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\" % (0,\n",
    "                                                                     data[0], \n",
    "                                                                     data[1], \n",
    "                                                                     data[2], \n",
    "                                                                     data[3], \n",
    "                                                                     data[4], \n",
    "                                                                     data[5],\n",
    "                                                                     data[6],\n",
    "                                                                     data[7],\n",
    "                                                                     data[8],\n",
    "                                                                     data[9])\n",
    "        # Execute the SQL command\n",
    "    cursor.execute(sql)\n",
    "        # Commit your changes in the database\n",
    "    db.commit()\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def insert_bayes_probabilities(data):\n",
    "    db = connect()\n",
    "    cursor = db.cursor()\n",
    "    for i in range(len(data)):\n",
    "        sql = \"INSERT INTO bayes_probabilities\"\n",
    "        sql += \"(CaseId,\"\n",
    "        sql += \"OmissionRawProbabilityADHD, \"\n",
    "        sql += \"OmissionRawProbabilityHealthy, \"\n",
    "        sql += \"CommissionRawProbabilityADHD, \"\n",
    "        sql += \"CommissionRawProbabilityHealthy, \"\n",
    "        sql += \"TargetRTVRawProbabilityADHD, \"\n",
    "        sql += \"TargetRTVRawProbabilityHealthy, \"\n",
    "        sql += \"DPrimeRawProbabilityADHD, \"\n",
    "        sql += \"DPrimeRawProbabilityHealthy, \"\n",
    "        sql += \"BetaRawProbabilityADHD, \"\n",
    "        sql += \"BetaRawProbabilityHealthy, \"\n",
    "        sql += \"totalRawProbabilityADHD, \"\n",
    "        sql += \"totalRawProbabilityHealthy, \"\n",
    "        sql += \"priors, \"\n",
    "        sql += \"finalProbabilityOfADHD) \"\n",
    "        sql += \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\" % (np.int(i),\n",
    "                                                                                         data[i, 0], \n",
    "                                                                                         data[i, 1], \n",
    "                                                                                         data[i, 2], \n",
    "                                                                                         data[i, 3], \n",
    "                                                                                         data[i, 4], \n",
    "                                                                                         data[i, 5],\n",
    "                                                                                         data[i, 6],\n",
    "                                                                                         data[i, 7],\n",
    "                                                                                         data[i, 8],\n",
    "                                                                                         data[i, 9],\n",
    "                                                                                         data[i, 10],\n",
    "                                                                                         data[i, 11],\n",
    "                                                                                         data[i, 12],\n",
    "                                                                                         data[i, 13]) \n",
    "        # Execute the SQL command\n",
    "        cursor.execute(sql)\n",
    "        # Commit your changes in the database\n",
    "        db.commit()\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#main function\n",
    "def main_bayes_boundary(caseIds):\n",
    "    allPatients = get_individual_data(caseIds, True)   \n",
    "    probData = get_probability_data(True)\n",
    "    \n",
    "    cutoffs = get_distribution_cutoff(probData)\n",
    "    insert_cutoffs(cutoffs)\n",
    "    \n",
    "    probabilities = get_probabilities(allPatients[:, 1:])\n",
    "    insert_bayes_probabilities(probabilities)\n",
    "    \n",
    "    return probData\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  90.0 %\n"
     ]
    }
   ],
   "source": [
    "#calls main from here:\n",
    "bayesData = main_bayes_boundary(np.arange(1, 21, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
